# ğŸ  House Prices Prediction (Ames, Iowa)

Ce projet vise Ã  prÃ©dire le prix de vente de maisons Ã  Ames (Iowa) Ã  partir de caractÃ©ristiques disponibles dans un jeu de donnÃ©es fourni par Kaggle.

> ğŸ¯ Objectif : construire un modÃ¨le de machine learning performant pour estimer les `SalePrice` Ã  partir des variables dâ€™entrÃ©e (`train.csv`) et soumettre les prÃ©dictions sur `test.csv`.

---

## ğŸ“ Structure du projet

```
house-prices-prediction/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train.csv
â”‚   â”œâ”€â”€ test.csv
â”‚   â””â”€â”€ data_description.txt
â”œâ”€â”€ 01_exploration.ipynb
â”œâ”€â”€ 02_preprocessing.ipynb
â”œâ”€â”€ 03_modelisation.ipynb
â”œâ”€â”€ 03_modelisation_avancee.ipynb
â”œâ”€â”€ 04_prediction.ipynb
â”œâ”€â”€ 05_optimisation.ipynb
â”œâ”€â”€ 06_prediction_optimisee.ipynb
â”œâ”€â”€ submission_optimisee.csv
â””â”€â”€ README.md
```

---

## ğŸ” Jeu de donnÃ©es

- DonnÃ©es disponibles sur Kaggle :  
  ğŸ‘‰ [House Prices - Advanced Regression Techniques](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques)

- 79 variables dâ€™entrÃ©e : surface, qualitÃ© des matÃ©riaux, annÃ©e de construction, nombre de piÃ¨ces, etc.

---

## ğŸ§ª MÃ©thodologie

1. **Exploration des donnÃ©es** : dÃ©tection des valeurs manquantes, distributions, corrÃ©lations.
2. **PrÃ©traitement** :
   - Imputation des valeurs manquantes
   - Encodage One-Hot des variables catÃ©gorielles
3. **ModÃ©lisation** :
   - RÃ©gression LinÃ©aire
   - Random Forest
   - Gradient Boosting
   - XGBoost
4. **Optimisation** :
   - `GridSearchCV` sur Gradient Boosting et XGBoost
   - Validation croisÃ©e (5-fold) avec RMSE
5. **PrÃ©diction finale** :
   - ModÃ¨le final entraÃ®nÃ© sur 100 % des donnÃ©es avec les meilleurs hyperparamÃ¨tres
   - PrÃ©dictions enregistrÃ©es dans `submission_optimisee.csv`

---

## ğŸ“ˆ RÃ©sultats

| ModÃ¨le                 | RMSE (validation croisÃ©e) |
|------------------------|----------------------------|
| RÃ©gression LinÃ©aire    | 31â€¯001                     |
| Random Forest          | 29â€¯050                     |
| Gradient Boosting      | **25â€¯685** âœ…               |
| XGBoost                | 25â€¯767                     |

---

## ğŸ“¤ Fichier de soumission

Le fichier final `submission_optimisee.csv` respecte le format demandÃ© par Kaggle :

```csv
Id,SalePrice
1461,169277.6
1462,187000.0
...
```

---

## ğŸ› ï¸ Stack technique

- Python, Pandas, Numpy
- Scikit-learn, XGBoost, LightGBM
- Matplotlib, Seaborn
- Jupyter Notebook

---

## ğŸ’¡ Ã€ venir (amÃ©liorations possibles)

- Transformation `log(SalePrice)` pour optimiser le score Kaggle
- Feature Engineering avancÃ©
- Stacking ou blending de modÃ¨les

---

## âœï¸ Autrice

ğŸ‘¤ **Florence Josse**  
ğŸ“ [Profil LinkedIn](https://www.linkedin.com/in/florence-josse-94875ab3/)

---

## ğŸ“Œ Remerciements

Merci Ã  la communautÃ© Kaggle pour la mise Ã  disposition du dataset et des notebooks inspirants.


